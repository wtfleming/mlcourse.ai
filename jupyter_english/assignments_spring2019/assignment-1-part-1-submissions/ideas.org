For medium - start with 3
  add features from 2





What does this mean?  Bad news in the end: our CV scheme is not perfect. Try to improve it! (hint: is all training set needed for a good prediction?).
  Does that mean we can drop the first 2 buckets, since they are so much lower in score?


  train_df = train_df.iloc[46102:]


See if there is anything specific to alice - ie always goes to a site on a specific day of the week (or weekend)?



Add some of the time features even though they drop cv score, compare to public LB

Double up the site1 to 5 features, does it improve score further?

find a better site 1 to 5 feature, funcition that checks all 10 sites?


https://stats.stackexchange.com/questions/14099/using-k-fold-cross-validation-for-time-series-model-selection




Try fewer splits in time_split = TimeSeriesSplit(n_splits=10)


Try some different logistic regression settings
Try liblinear (and the other ones)

Try different algorithms other than logistic regression
  SGDClassifier  - what does the leaderboard score look like with it? what else?




* --------------------------- Medium claps count competition ---------------------------

* TODO Read https://scikit-learn.org/stable/modules/feature_extraction.html


* TODO Use SGDRegressor for testing because it is faster

* TODO Look at all kernels available https://www.kaggle.com/c/how-good-is-your-medium-article/kernels


* TODO Figure out how to do cross validation with sgd
something like this? http://facweb.cs.depaul.edu/mobasher/classes/CSC478/Notes/IPython%20Notebook%20-%20Regression.html


* DONE The onehotencoder for authors is not working right?  Or maybe it is - they are combined
cat train_author.txt | sort -rn | uniq | wc -l
   32182
cat test_author.txt | sort -rn | uniq | wc -l
   18842

c -l train_author.txt
   62313 train_author.txt

wc -l test_author.txt
   34645 test_author.txt



* TODO try sgd with a gridcv search



* TODO Try different params with sgd like
sgdreg = SGDRegressor(penalty='l2', alpha=0.15, n_iter=200)

https://scikit-learn.org/stable/modules/sgd.html


* TODO Scale the tf-idf features to be between 0.0 and 1.0?


* DONE Add time features: publication hour, whether it's morning, day, night, whether it's a weekend


* TODO add content length as a feature





* TODO You may not ignore HTML and extract some features from there

* TODO You'd better experiment with your validation scheme. You should see a correlation between your local improvements and LB score

* TODO Try TF-IDF, ngrams, Word2Vec and GloVe embeddings

* TODO Try various NLP techniques like stemming and lemmatization

* TODO Tune hyperparameters. In our example, we've left only 50k features and used C=1 as a regularization parameter, this can be changed

* TODO SGD and Vowpal Wabbit will learn much faster

* TODO Play around with blending and/or stacking. An intro is given in this Kernel by @yorko https://www.kaggle.com/kashnitsky/ridge-and-lightgbm-blending-hacking




* TODO Do data exploration

* TODO look at all fields available in the json
['_id', '_timestamp', '_spider', 'url', 'domain', 'published',
 'title', 'content', 'author', 'image_url', 'tags', 'link_tags', 'meta_tags']




* TODO Try to determine language content is written in as a feature?

* TODO LDA to generate content topics?
https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html


* TODO K-nearest neighbors on content to generate feature / topics?

* TODO K-means on content to create groups which can be used as a feature?



* --------------------------- Website timeseries competition ---------------------------

* TODO Look at new kernel published https://www.kaggle.com/kashnitsky/model-validation-in-a-competition

* TODO Figure out how to use eli5 like in here https://www.kaggle.com/kashnitsky/model-validation-in-a-competition


* TODO Submit top entry, but with liblinear to compare scores

* TODO add a max_iter to the top entry lbfgs and see if it is a better score


* TODO Try increasing and decreasing the number of splits:   time_split = TimeSeriesSplit(n_splits=10)

* TODO For social media - instead of 5 features per site, look at all 10 sites and create a didVisitSite single feature for each site



* TODO Feature - isWeekend?




* TODO Look at the class notebooks for linear models



* DONE One hot encode the year-month category?
Seems to hurt the cross validation score?

There's a cluster of months target is more common in
Should help with the months target was not active at all?




* TODO Are there any sites that the target visits that are not common in the dataset? Or vice versa?
In other words, sites the target visits, but just about no body else does?
How can that be stored as a feature?


https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html
says "Equivalent to CountVectorizer followed by TfidfTransformer."




* TODO Any features that can be combined?

* TODO What can I do with TF-IDF?




* DONE Target sessions seems to be shorter than 40 seconds
Neither moved the needle too much?

total_num_sessions: 2297
num_gte_40_seconds: 554
0.2411841532433609


Much more often then the others
total_num_sessions: 251264
num_gte_40_seconds: 109122
0.43429221854304634


At 100 seconds
total_num_sessions: 2297
num_gte_40_seconds: 237
0.10317805833696125

total_num_sessions: 251264
num_gte_40_seconds: 67738
0.26958895822720325




* TODO Session length
* TODO avg Number of sites visited in a session
