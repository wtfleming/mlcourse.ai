
* --------------------------- Medium claps count competition ---------------------------

* TODO try sgd with a gridcv search

* TODO Figure out how to do cross validation with sgd
something like this? http://facweb.cs.depaul.edu/mobasher/classes/CSC478/Notes/IPython%20Notebook%20-%20Regression.html


* TODO Try different params with sgd like
sgdreg = SGDRegressor(penalty='l2', alpha=0.15, n_iter=200)

https://scikit-learn.org/stable/modules/sgd.html


* TODO Scale the tf-idf features to be between 0.0 and 1.0?


* DONE Add time features: publication hour, whether it's morning, day, night, whether it's a weekend


* TODO add content length as a feature

* TODO Look at all kernels available https://www.kaggle.com/c/how-good-is-your-medium-article/kernels



* TODO You may not ignore HTML and extract some features from there

* TODO You'd better experiment with your validation scheme. You should see a correlation between your local improvements and LB score

* TODO Try TF-IDF, ngrams, Word2Vec and GloVe embeddings

* TODO Try various NLP techniques like stemming and lemmatization

* TODO Tune hyperparameters. In our example, we've left only 50k features and used C=1 as a regularization parameter, this can be changed

* TODO SGD and Vowpal Wabbit will learn much faster

* TODO Play around with blending and/or stacking. An intro is given in this Kernel by @yorko https://www.kaggle.com/kashnitsky/ridge-and-lightgbm-blending-hacking




* TODO Do data exploration

* TODO look at all fields available in the json
['_id', '_timestamp', '_spider', 'url', 'domain', 'published',
 'title', 'content', 'author', 'image_url', 'tags', 'link_tags', 'meta_tags']




* TODO Try to determine language content is written in as a feature?

* TODO LDA to generate content topics?
https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html


* TODO K-nearest neighbors on content to generate feature / topics?

* TODO K-means on content to create groups which can be used as a feature?



* --------------------------- Website timeseries competition ---------------------------

* TODO Look at new kernel published https://www.kaggle.com/kashnitsky/model-validation-in-a-competition


* TODO Submit top entry, but with liblinear to compare scores

* TODO add a max_iter to the top entry lbfgs and see if it is a better score


* TODO Try increasing and decreasing the number of splits:   time_split = TimeSeriesSplit(n_splits=10)

* TODO For social media - instead of 5 features per site, look at all 10 sites and create a didVisitSite single feature for each site



* TODO Feature - isWeekend?




* TODO Look at the class notebooks for linear models



* DONE One hot encode the year-month category?
Seems to hurt the cross validation score?

There's a cluster of months target is more common in
Should help with the months target was not active at all?




* TODO Are there any sites that the target visits that are not common in the dataset? Or vice versa?
In other words, sites the target visits, but just about no body else does?
How can that be stored as a feature?


https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html
says "Equivalent to CountVectorizer followed by TfidfTransformer."




* TODO Any features that can be combined?

* TODO What can I do with TF-IDF?




* DONE Target sessions seems to be shorter than 40 seconds
Neither moved the needle too much?

total_num_sessions: 2297
num_gte_40_seconds: 554
0.2411841532433609


Much more often then the others
total_num_sessions: 251264
num_gte_40_seconds: 109122
0.43429221854304634


At 100 seconds
total_num_sessions: 2297
num_gte_40_seconds: 237
0.10317805833696125

total_num_sessions: 251264
num_gte_40_seconds: 67738
0.26958895822720325




* TODO Session length
* TODO avg Number of sites visited in a session
