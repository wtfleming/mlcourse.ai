{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import Ridge\n",
    "#import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will help to throw away all HTML tags from article content/title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supplementary function to read a JSON line without crashing on escape characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_line(line=None):\n",
    "    result = None\n",
    "    try:        \n",
    "        result = json.loads(line)\n",
    "    except Exception as e:      \n",
    "        # Find the offending character index:\n",
    "        idx_to_replace = int(str(e).split(' ')[-1].replace(')',''))      \n",
    "        # Remove the offending character:\n",
    "        new_line = list(line)\n",
    "        new_line[idx_to_replace] = ' '\n",
    "        new_line = ''.join(new_line)     \n",
    "        return read_json_line(line=new_line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a JSON and forms a txt file leaving only article titles. When you resort to feature engineering and extract various features from articles, a good idea is to modify this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_titles_from_json(path_to_inp_json_file, path_to_out_txt_file, total_length):\n",
    "    '''\n",
    "    :param path_to_inp_json_file: path to a JSON file with train/test data\n",
    "    :param path_to_out_txt_file: path to extracted features (here titles), one per line\n",
    "    :param total_length: we'll pass the hardcoded file length to make tqdm even more convenient\n",
    "    '''\n",
    "    with open(path_to_inp_json_file, encoding='utf-8') as inp_file, \\\n",
    "         open(path_to_out_txt_file, 'w', encoding='utf-8') as out_file:\n",
    "        for line in tqdm_notebook(inp_file, total=total_length):\n",
    "            json_data = read_json_line(line)\n",
    "            content = json_data['title'].replace('\\n', ' ').replace('\\r', ' ')\n",
    "            content_no_html_tags = strip_tags(content)\n",
    "            out_file.write(content_no_html_tags + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5558ee21a6764c2d957a89033749cbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=62313), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 13.1 s, sys: 880 ms, total: 14 s\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "extract_titles_from_json(path_to_inp_json_file=os.path.join(PATH_TO_DATA, 'train.json'),\n",
    "           path_to_out_txt_file='train_titles.txt', total_length=62313)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba39a7b53524310a741cf959c7fe637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=34645), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 7.34 s, sys: 466 ms, total: 7.8 s\n",
      "Wall time: 7.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "extract_titles_from_json(path_to_inp_json_file=os.path.join(PATH_TO_DATA, 'test.json'),\n",
    "           path_to_out_txt_file='test_titles.txt', total_length=34645)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering (simple Tf-Idf for titles)¶\n",
    "We'll use a very simple feature extractor – TfidfVectorizer, meaning that we resort to the Bag-of-Words approach. For now, we are leaving only 50k features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=50000, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.3 s, sys: 153 ms, total: 4.45 s\n",
      "Wall time: 3.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('train_titles.txt', encoding='utf-8') as input_train_file:\n",
    "    X_train = tfidf.fit_transform(input_train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 703 ms, sys: 5.97 ms, total: 709 ms\n",
      "Wall time: 709 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('test_titles.txt', encoding='utf-8') as input_test_file:\n",
    "    X_test = tfidf.transform(input_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 50000), (34645, 50000))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read targets from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv(os.path.join(PATH_TO_DATA, \n",
    "                                        'train_log1p_recommends.csv'), \n",
    "                           index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_target['log_recommends'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target is still somewhat skewed, though it's allready log1p-transformed (#claps with log1p transformation). Yet, we'll apply log1p once more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train, bins=30, alpha=.5, color='red', \n",
    "         label='original', range=(0,10));\n",
    "plt.hist(np.log1p(y_train), bins=30, alpha=.5, color='green', \n",
    "         label='log1p', range=(0,10));\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and model training\n",
    "Let's make a 30%-holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_size = int(0.7 * train_target.shape[0])\n",
    "X_train_part = X_train[:train_part_size, :]\n",
    "y_train_part = y_train[:train_part_size]\n",
    "X_valid =  X_train[train_part_size:, :]\n",
    "y_valid = y_train[train_part_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to fit a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.33 s, sys: 4.92 ms, total: 1.34 s\n",
      "Wall time: 404 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=17, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ridge.fit(X_train_part, np.log1p(y_train_part));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After log1p-transformation, we need to apply an inverse  expm1-trasformation to predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pred = np.expm1(ridge.predict(X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we fit a LightGBM model with mean_absolute_error as objective (it's important!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_x_train_part = lgb.Dataset(X_train_part.astype(np.float32), label=np.log1p(y_train_part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_x_valid = lgb.Dataset(X_valid.astype(np.float32), label=np.log1p(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param = {'num_leaves': 255, \n",
    "#         'objective': 'mean_absolute_error',\n",
    "#         'metric': 'mae'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_round = 200\n",
    "# bst_lgb = lgb.train(param, lgb_x_train_part, num_round, valid_sets=[lgb_x_valid], early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_pred = np.expm1(bst_lgb.predict(X_valid.astype(np.float32), num_iteration=bst_lgb.best_iteration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot predictions and targets for the holdout set. Recall that these are #recommendations (= #claps) of Medium articles with the  np.log1p transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(y_valid, bins=30, alpha=.5, color='red', label='true', range=(0,10));\n",
    "#plt.hist(ridge_pred, bins=30, alpha=.5, color='green', label='Ridge', range=(0,10));\n",
    "#plt.hist(lgb_pred, bins=30, alpha=.5, color='blue', label='Lgbm', range=(0,10));\n",
    "#plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the prediction is far from perfect, and we get MAE  ≈  1.3 that corresponds to  ≈  2.7 error in #recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2521077393066944"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_valid_mae = mean_absolute_error(y_valid, ridge_pred)\n",
    "ridge_valid_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_valid_mae = mean_absolute_error(y_valid, lgb_pred)\n",
    "# lgb_valid_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple blending\n",
    "Now let's mix predictions. We's just pick up weights 0.6 for Lgbm and 0.4 for Ridge, but these are typically tuned via cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_absolute_error(y_valid, .4 * lgb_pred + .6 * ridge_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train both models on the full accessible training set, make predictions for the test set and form submission files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 s, sys: 7.99 ms, total: 1.62 s\n",
      "Wall time: 684 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=17, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ridge.fit(X_train, np.log1p(y_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 ms, sys: 651 µs, total: 15.8 ms\n",
      "Wall time: 5.94 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ridge_test_pred = np.expm1(ridge.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb_x_train = lgb.Dataset(X_train.astype(np.float32), label=np.log1p(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_round = 60\n",
    "#bst_lgb = lgb.train(param, lgb_x_train, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb_test_pred = np.expm1(bst_lgb.predict(X_test.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix_pred = .4 * lgb_test_pred + .6 * ridge_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaderboard probing\n",
    "Now we apply a dirty hack. Originally, we made you come up with it by your own (as a part of an assignment, with only a hint from out side), but now it's described in this tutorial, written within a previous session of mlcourse.ai.\n",
    "\n",
    "Submitting all zeros gives 4.33328. If you take a pen and a piece of paper and figure out what it means for MAE that all predictions are zeros, then you'll see that it's exactly the mean target value for the test set. We can compare it with mean target for training data and correspondingly adjust predictions. Looks like a dirty hack, however, the same thing is often done with time series prediction (even in production) - merely adjusting your predictions to a change in target variable distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_target = 4.33328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix_test_pred_modif = mix_pred + mean_test_target - y_train.mean()\n",
    "#mix_test_pred_modif = ridge_test_pred + mean_test_target - y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_file(prediction, filename,\n",
    "                          path_to_sample=os.path.join(PATH_TO_DATA, 'sample_submission.csv')):\n",
    "    submission = pd.read_csv(path_to_sample, index_col='id')\n",
    "    \n",
    "    submission['log_recommends'] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_submission_file(ridge_test_pred, 'submissions/03-medium-submission.csv') # 2.03034 # no probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.65253\n",
    "write_submission_file(ridge_test_pred + mean_test_target - y_train.mean(), 'submissions/03-ridge_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_submission_file(lgb_test_pred + mean_test_target - y_train.mean(), 'submissions/03-lgb_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_submission_file(mix_test_pred_modif, 'submissions/03-medium-submission-probing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, simple blending decreases MAE for both holdout predictions and on the leaderboard. However, I don't recommend to play with blending/stacking schemes un the beginning of the competition – it's crucially important to come up with good features first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can further improve your model in various ways. I've described them in this kernel. Go and compete, good luck! https://www.kaggle.com/kashnitsky/ridge-countvectorizer-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO look at the leaderboard probing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO implement this part from https://www.kaggle.com/kashnitsky/ridge-and-lightgbm-blending-hacking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
